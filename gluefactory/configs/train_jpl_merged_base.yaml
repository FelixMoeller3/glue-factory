# This is a basic config for the merged dataset with combining minidepth and oxparis with multiscale training. I copied the datasets configs(minidepth, oxparis) from the respective base configs
data:
    name: gluefactory.datasets.merge_datasets
    train_batch_size: 8  # batch size is for all GPUS
    val_batch_size: 8
    num_workers: 16  # number of workers used by the Dataloader: recommended 4 * n_gpus (also given for all gpus)
    prefetch_factor: 2 # preload 2 batches per worker
    inter_dataset_shuffle: True  # if True, all images are shuffled (from all datasets) -> scale selection needs to be random in this case as otherwise datsaets will have always choosing same size
    use_multiscale_learning: False  # if True, we assume that all datasets included use multiscale learning. -> will make the datasets output same size for a batch
    datasets: # Here list datasets with their (file)name. As an example we have Oxparis and Minidepth here
        scannet:
            name: "gluefactory.datasets.scannet"
            data_dir: "scannet"  # as subdirectory of DATA_PATH(defined in settings.py)
            grayscale: false
            reshape: 800
            square_pad: true  # square padding is needed to batch together images with current scaling technique(keeping aspect ratio). Can and should be deactivated on benchmarks
            multiscale_learning:
                do: false
                scale_selection: random  # random or round-robin
            load_features:
                do: True
                check_exists: True
                point_gt:
                    load_points: False  # load actual keypoint locations or not (the heatmap constructed from kp  is loaded anyway)
                    max_num_keypoints: 1500
                    max_num_heatmap_keypoints: 1500
                    # -> Can also be set to None to return all points but this can only be used when batchsize=1. Min num kp in oxparis: 63
                    use_score_heatmap: False
                line_gt:
                    load_lines: False # load ground truth deeplsd lines
                    enforce_threshold: 5.0  # Enforce values in distance field to be no greater than this value
            train_scene_list: gluefactory/datasets/scannetv2_train.txt
            val_scene_list: gluefactory/datasets/scannetv2_val.txt
            # img list path from repo root -> use checked in file list, it is similar to pold2 file
            val_size: 500  # number of val images
            train_size: 11500
        oxparis:
            name: "gluefactory.datasets.oxford_paris_mini_1view_jpldd"
            data_dir: "revisitop1m_POLD2/jpg"
            grayscale: False
            reshape: 800
            square_pad: True
            multiscale_learning:
                do: False
                scales_list: [800, 600, 400]
                scale_selection: 'random'
            load_features:
                do: True
                check_exists: True
                point_gt:
                    # ATTENTION: if deeplsd line ep are used as kp gt, using score heatmap is discouraged, as deeplsd does not assign scores to line ep and thus we set all to one
                    load_points: False
                    use_score_heatmap: False
                    max_num_heatmap_keypoints: -1
                    max_num_keypoints: 63
                    use_deeplsd_lineendpoints_as_kp_gt: False  # set true to use deep-lsd line endpoints as keypoint groundtruth
                    use_superpoint_kp_gt: True  # set true to use default HA-Superpoint groundtruth
                line_gt:
                    enforce_threshold: 5.0
                augment: # activate or deactivate data augmentation
                    do: False
                    type: "dark" # choose identity, dark or lg
            val_size: 500
            train_size: 11500

model:
    name: joint_point_line_extractor
    model_name: "aliked-n16"
    line_neighborhood: 5
    max_num_keypoints: 1500  # setting for training, for eval: -1
    subpixel_refinement: True
    use_line_anglefield: False   # if set to false, model will be initialized without AF branch and AF will not be output or considered in inference or training
                                # In that case make sure the line detection does not expect AF input!
    line_df_decoder_channels: 64  # number of channels in CNN for af/df decoder branches
    training:
        do: True
        aliked_pretrained: True
        pretrain_kp_decoder: True
        train_descriptors:
            do: True # if train is True, initialize ALIKED Light model form OTF Descriptor GT
            gt_aliked_model: "aliked-n32"
        loss:
            kp_loss_name: "focal_loss"
            kp_loss_parameters:
                lambda_weighted_bce: 200
                focal_alpha: 0.25
                focal_gamma: 2
            loss_weights:
                line_af_weight: 1
                line_df_weight: 1
                keypoint_weight: 1
                descriptor_loss: 1
    line_detection:
      do: False
    checkpoint: null  # if given load model weights from this checkpoint
    timeit: False  # override timeit: False from BaseModel
train:
    load_experiment: null  # initialize the model from a previous experiment (take weights)
    seed: 7
    epochs: 60
    log_every_iter: 8
    eval_every_iter: 15000 # automatically creates new checkpoint if new best eval metric is reached -> set > #batches to not eval except at the end of each epoch
    save_every_iter: 10000
    test_every_epoch: -1
    optimizer: "adam"
    best_key: "loss/total" # key used to determine best checkpoint and evaluation progress
    lr: 0.0001
    lr_schedule:
        type: 'ReduceLROnPlateau'
        on_epoch: True
        options:
            patience: 5
    keep_last_checkpoints: 5
    submodules: []

