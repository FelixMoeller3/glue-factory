data:
    name: gluefactory.datasets.minidepth
    data_dir: "minidepth"  # as subdirectory of DATA_PATH(defined in settings.py)
    grayscale: False
    num_workers: 16  # number of workers used by the Dataloader: recommended 4 * n_gpus (also given for all gpus)
    train_batch_size: 8  # given for all gpus
    val_batch_size: 8
    prefetch_factor: 2 # preload 2 batches per worker
    reshape: 800  # new resizing keeps aspect ratio so quadratic image is not guaranteed
    square_pad: True # thus for a batchsize > 1 square padding needs to be activated for batching
    multiscale_learning:
        do: False  # to use multiscale training, reshape must be set to false
        scales_list: [1000, 800, 600, 400]
        scale_selection: 'random' # random or round-robin
    load_features:
        do: True
        check_exists: True
        point_gt:            
            # ATTENTION: if deeplsd line ep are used as kp gt, using score heatmap is discouraged, as deeplsd does not assign scores to line ep and thus we set all to one
            use_score_heatmap: False
            max_num_keypoints: 1500
            max_num_heatmap_keypoints: 1500
            use_deeplsd_lineendpoints_as_kp_gt: False  # set true to use deep-lsd line endpoints as keypoint groundtruth
            use_superpoint_kp_gt: True  # set true to use default HA-Superpoint groundtruth
        line_gt:
            enforce_threshold: 5.0
        augment: # activate or deactivate data augmentation
            do: False
            type: "dark" # choose identity, dark or lg
    train_scenes_file_path: "gluefactory/datasets/minidepth_train_scenes.txt"  # path to training scenes file where train scenes from megadepth1500 are excluded, based on repo root
    val_scenes_file_path: "gluefactory/datasets/minidepth_val_scenes.txt"
    
model:
    name: joint_point_line_extractor
    model_name: "aliked-n16"
    line_neighborhood: 5
    max_num_keypoints: 1500  # setting for training, for eval: -1
    subpixel_refinement: True
    use_line_anglefield: False   # if set to false, model will be initialized without AF branch and AF will not be output or considered in inference or training
                                # In that case make sure the line detection does not expect AF input!
    line_df_decoder_channels: 64  # number of channels in CNN for af/df decoder branches
    training:
        do: True
        aliked_pretrained: True
        pretrain_kp_decoder: True
        train_descriptors:
            do: True # if train is True, initialize ALIKED Light model form OTF Descriptor GT
            gt_aliked_model: "aliked-n32"
        loss:
            kp_loss_name: "focal_loss"
            kp_loss_parameters:
                lambda_weighted_bce: 200
                focal_alpha: 0.25
                focal_gamma: 2
            loss_weights:
                line_af_weight: 1
                line_df_weight: 1
                keypoint_weight: 1
                descriptor_loss: 1
    line_detection:
      do: False
    checkpoint: null  # if given load model weights from this checkpoint
    timeit: False  # override timeit: False from BaseModel
train:
    load_experiment: null  # initialize the model from a previous experiment (take weights)
    seed: 7
    epochs: 60
    log_every_iter: 8
    eval_every_iter: 15000 # automatically creates new checkpoint if new best eval metric is reached -> set > #batches to not eval except at the end of each epoch
    save_every_iter: 10000
    test_every_epoch: -1 # check if test deactivated
    optimizer: "adam"
    best_key: "loss/total" # key used to determine best checkpoint and evaluation progress
    lr: 0.0001
    lr_schedule:
        type: 'ReduceLROnPlateau'
        on_epoch: True
        options:
            patience: 5
    keep_last_checkpoints: 5
    submodules: []
    timeit: False    # print jpldd model mean timings every epoch

